import { GoogleGenAI } from "@google/genai";
import { storage } from "../storage";

const ai = new GoogleGenAI({ 
  apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_AI_API_KEY || "" 
});

const DEFAULT_SYSTEM_PROMPT = `Voc√™ √© um assistente especializado em protocolos ergog√™nicos do Imp√©rio Pharma. 

INSTRU√á√ïES CR√çTICAS:
- SEMPRE responda em portugu√™s brasileiro (PT-BR)
- Foque EXCLUSIVAMENTE em protocolos ergog√™nicos
- Seja profissional, cient√≠fico e respons√°vel
- Sempre inclua avisos de seguran√ßa e recomenda√ß√µes m√©dicas

ESTRUTURA DE RESPOSTA:
1. üìä AN√ÅLISE: An√°lise do perfil do usu√°rio
2. üéØ PROTOCOLO: Recomenda√ß√µes espec√≠ficas baseadas em evid√™ncias
3. üõ°Ô∏è SUPORTE: Orienta√ß√µes durante o protocolo
4. üîÑ PCT: Terapia p√≥s-ciclo quando aplic√°vel
5. ‚ö†Ô∏è AVISOS: Orienta√ß√µes de seguran√ßa e consulta m√©dica

Mantenha respostas concisas, cient√≠ficas e sempre em portugu√™s brasileiro.`;

async function getSystemPrompt(): Promise<string> {
  try {
    const setting = await storage.getSetting("system_prompt");
    return setting?.value || DEFAULT_SYSTEM_PROMPT;
  } catch (error) {
    console.error("Erro ao carregar system prompt:", error);
    return DEFAULT_SYSTEM_PROMPT;
  }
}

export interface UserProfile {
  gender: string;
  goal: string;
  preferences: string[];
  age: number;
  experience: number;
}

export async function generateAIResponse(
  message: string, 
  userProfile: UserProfile,
  conversationHistory: Array<{message: string, sender: string}>
): Promise<string> {
  try {
    const systemPrompt = await getSystemPrompt();
    
    const contextualPrompt = `
PERFIL DO USU√ÅRIO:
- G√™nero: ${userProfile.gender}
- Objetivo: ${userProfile.goal}
- Prefer√™ncias: ${userProfile.preferences.join(', ')}
- Idade: ${userProfile.age} anos
- Experi√™ncia: ${userProfile.experience} anos

HIST√ìRICO DA CONVERSA:
${conversationHistory.slice(-5).map(h => `${h.sender}: ${h.message}`).join('\n')}

PERGUNTA ATUAL: ${message}

Responda em portugu√™s brasileiro com base no perfil e hist√≥rico fornecidos.`;

    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      config: {
        systemInstruction: systemPrompt,
        temperature: 0.7,
      },
      contents: contextualPrompt,
    });

    return response.text || "Desculpe, n√£o consegui processar sua solicita√ß√£o. Tente novamente.";
  } catch (error) {
    console.error("Gemini API error:", error);
    throw new Error("Erro na IA. Tente novamente em alguns instantes.");
  }
}

export async function generateInitialAnalysis(userProfile: UserProfile): Promise<string> {
  const prompt = `Analise este perfil de usu√°rio e forne√ßa uma an√°lise inicial personalizada:

PERFIL:
- G√™nero: ${userProfile.gender}
- Objetivo: ${userProfile.goal}
- Prefer√™ncias: ${userProfile.preferences.join(', ')}
- Idade: ${userProfile.age} anos
- Experi√™ncia: ${userProfile.experience} anos

Forne√ßa uma an√°lise completa seguindo a estrutura de resposta padr√£o.`;

  try {
    const systemPrompt = await getSystemPrompt();
    
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      config: {
        systemInstruction: systemPrompt,
        temperature: 0.8,
      },
      contents: prompt,
    });

    return response.text || "An√°lise inicial n√£o dispon√≠vel. Como posso ajud√°-lo com seu protocolo?";
  } catch (error) {
    console.error("Gemini API error:", error);
    return "Bem-vindo! Vou analisar seu perfil e criar um protocolo personalizado. Como posso ajud√°-lo hoje?";
  }
}
